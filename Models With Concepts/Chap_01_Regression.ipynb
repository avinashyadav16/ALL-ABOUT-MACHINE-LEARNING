{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # LECTURE - 01\n",
    ">\n",
    "> ### INTRODUCTION TO LINEAR REGRESSION: STOCK PREDICTION<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "- The Idea of the regression is to take continuous data and \n",
    "  figure out the best fit line for that data.\n",
    "\n",
    "- With Linear Regression, we try to model our data with a straight line.\n",
    "\n",
    "- Equation of the stringht line is: y = mx + c\n",
    "    if we have x, we can figure out y given that we have m and c\n",
    "\n",
    "- Basically the whole point of the regresion is to find out what m and c is.\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "- With ML, especially with Supervised ML, everything boils down to Features(are Attributes, in the below case it is continous data)\n",
    "  and Lebels.\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, model_selection, svm\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Open    High     Low    Close      Volume  Ex-Dividend  \\\n",
      "Date                                                                   \n",
      "2004-08-19  100.01  104.06   95.96  100.335  44659000.0          0.0   \n",
      "2004-08-20  101.01  109.08  100.50  108.310  22834300.0          0.0   \n",
      "2004-08-23  110.76  113.48  109.05  109.400  18256100.0          0.0   \n",
      "2004-08-24  111.24  111.60  103.57  104.870  15247300.0          0.0   \n",
      "2004-08-25  104.76  108.00  103.88  106.000   9188600.0          0.0   \n",
      "\n",
      "            Split Ratio  Adj. Open  Adj. High   Adj. Low  Adj. Close  \\\n",
      "Date                                                                   \n",
      "2004-08-19          1.0  50.159839  52.191109  48.128568   50.322842   \n",
      "2004-08-20          1.0  50.661387  54.708881  50.405597   54.322689   \n",
      "2004-08-23          1.0  55.551482  56.915693  54.693835   54.869377   \n",
      "2004-08-24          1.0  55.792225  55.972783  51.945350   52.597363   \n",
      "2004-08-25          1.0  52.542193  54.167209  52.100830   53.164113   \n",
      "\n",
      "            Adj. Volume  \n",
      "Date                     \n",
      "2004-08-19   44659000.0  \n",
      "2004-08-20   22834300.0  \n",
      "2004-08-23   18256100.0  \n",
      "2004-08-24   15247300.0  \n",
      "2004-08-25    9188600.0  \n"
     ]
    }
   ],
   "source": [
    "df = quandl.get('WIKI/GOOGL')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>In Machine Learning, We can have all the features we want but we need to have only some meaningful features, features that actually have to do something with our data.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of               Adj. Open    Adj. High     Adj. Low   Adj. Close  Adj. Volume\n",
      "Date                                                                       \n",
      "2004-08-19    50.159839    52.191109    48.128568    50.322842   44659000.0\n",
      "2004-08-20    50.661387    54.708881    50.405597    54.322689   22834300.0\n",
      "2004-08-23    55.551482    56.915693    54.693835    54.869377   18256100.0\n",
      "2004-08-24    55.792225    55.972783    51.945350    52.597363   15247300.0\n",
      "2004-08-25    52.542193    54.167209    52.100830    53.164113    9188600.0\n",
      "...                 ...          ...          ...          ...          ...\n",
      "2018-03-21  1092.570000  1108.700000  1087.210000  1094.000000    1990515.0\n",
      "2018-03-22  1080.010000  1083.920000  1049.640000  1053.150000    3418154.0\n",
      "2018-03-23  1051.370000  1066.780000  1024.870000  1026.550000    2413517.0\n",
      "2018-03-26  1050.600000  1059.270000  1010.580000  1054.090000    3272409.0\n",
      "2018-03-27  1063.900000  1064.540000   997.620000  1006.940000    2940957.0\n",
      "\n",
      "[3424 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "df = df[['Adj. Open', 'Adj. High', 'Adj. Low', 'Adj. Close', 'Adj. Volume']]\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage change in High to Low stock price:\n",
    "# This is almost percent votatility of the day\n",
    "# Therefore, we are gonna to define a new column: \"H2L_PerCng\"\n",
    "\n",
    "\n",
    "df['H2L_PerCng'] = (df['Adj. High'] - df['Adj. Close']) / \\\n",
    "    df['Adj. Close'] * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Features)\n",
    "# Daily Percentage change or the daily move in Close to Open stock price:\n",
    "# Normally the Percent Change is => ((New - Old) / (Old)) * 100\n",
    "\n",
    "df['Per_Cng'] = (df[\"Adj. Close\"] - df['Adj. Open']) / df['Adj. Open'] * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Adj. Close  H2L_PerCng   Per_Cng  Adj. Volume\n",
      "Date                                                     \n",
      "2004-08-19   50.322842    3.712563  0.324968   44659000.0\n",
      "2004-08-20   54.322689    0.710922  7.227007   22834300.0\n",
      "2004-08-23   54.869377    3.729433 -1.227880   18256100.0\n",
      "2004-08-24   52.597363    6.417469 -5.726357   15247300.0\n",
      "2004-08-25   53.164113    1.886792  1.183658    9188600.0\n"
     ]
    }
   ],
   "source": [
    "# (Features)\n",
    "# Defining the new dataframe, we want to work with or we do really care about:\n",
    "\n",
    "df = df[['Adj. Close', 'H2L_PerCng', 'Per_Cng', 'Adj. Volume']]\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "> # LECTURE - 02\n",
    ">\n",
    "> ### Features and Labels:\n",
    ">\n",
    "> Usually we define features by capital X and labels by small y.<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forecast_out is: 31 \n",
      "\n",
      "\n",
      "dataframe head is:\n",
      "             Adj. Close  H2L_PerCng   Per_Cng  Adj. Volume      label\n",
      "Date                                                                \n",
      "2004-08-19   50.322842    3.712563  0.324968   44659000.0  67.739104\n",
      "2004-08-20   54.322689    0.710922  7.227007   22834300.0  69.399229\n",
      "2004-08-23   54.869377    3.729433 -1.227880   18256100.0  68.752232\n",
      "2004-08-24   52.597363    6.417469 -5.726357   15247300.0  69.639972\n",
      "2004-08-25   53.164113    1.886792  1.183658    9188600.0  69.078238\n",
      "\n",
      "\n",
      "dataframe tail is:\n",
      "             Adj. Close  H2L_PerCng   Per_Cng  Adj. Volume   label\n",
      "Date                                                             \n",
      "2016-08-24      793.60    0.612399 -0.409106    1284437.0  800.71\n",
      "2016-08-25      791.30    0.432200 -0.088384    1202680.0  814.17\n",
      "2016-08-26      793.22    0.779103  0.092115    1248881.0  809.57\n",
      "2016-08-29      795.82    0.339273  0.349284     773698.0  811.77\n",
      "2016-08-30      791.92    0.767754 -0.121078    1167413.0  804.08\n"
     ]
    }
   ],
   "source": [
    "# It is just a variable created to work with the stock prices:\n",
    "forecast_col = 'Adj. Close'\n",
    "\n",
    "\n",
    "# Just in case there is not missing data\n",
    "# In case of missing data and we can't get rid of it, so we fill that column with some specific values:\n",
    "df.fillna(-9999, inplace=True)\n",
    "# We did this because, with ML we can't work with NaN data,\n",
    "# therefore we actually have to replace the NaN with something, or\n",
    "# we can get rid of the entire column.\n",
    "\n",
    "\n",
    "# Actually we are trying to predict the 10% of the dataframe to predict the forecast out:\n",
    "forecast_out = int(math.ceil(0.01 * len(df)))\n",
    "print(f'forecast_out is: {forecast_out} \\n\\n')\n",
    "\n",
    "# Creating label:\n",
    "# Since we have forecast_out, so we can create labels\n",
    "# Here we are using forecast_out as minus that's why we made it as int data type\n",
    "# So, basically we are shifting the columns negativelly upwards.\n",
    "df['label'] = df[forecast_col].shift(-forecast_out)\n",
    "# This way, each row, the label column for each row will be adjusted close price 10 days into the future.\n",
    "# So, that's our label.\n",
    "\n",
    "\n",
    "# So, this will just print first five rows of the dataframes\n",
    "print(f'dataframe head is:\\n {df.head()}\\n\\n')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(f'dataframe tail is:\\n {df.tail()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "> # LECTURE - 03\n",
    ">\n",
    "> ### Training and Testing: <br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Scaling our data aspect is usually done on the features.</li>\n",
    "<li>The goal is often to get our features to be somewhere between -1 and +1</li>\n",
    "<li>This can actaully just help with accuracy as well as just processing speed or how long it might take to actually do the calculations.</li>\n",
    "<br>\n",
    "\n",
    "<li>Here, we are gonna to use cross-validation to create our training and testing samples. It's a good way to split up our data, suffle it up.</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3321 3321\n"
     ]
    }
   ],
   "source": [
    "# so, our features are basically everything, except for the label column.\n",
    "# We can do this beacause df.drop() return new dataframes and\n",
    "# it can be converted to numpy array and here it is being saved to the value of the X.\n",
    "X = np.array(df.drop(['label'], axis=1))\n",
    "\n",
    "\n",
    "# Creating the labels:\n",
    "# Now the value of y is our labels :\n",
    "y = np.array(df['label'])\n",
    "\n",
    "\n",
    "# Now, we are going to scale X\n",
    "\n",
    "\n",
    "X = preprocessing.scale(X)\n",
    "\n",
    "\n",
    "# redefining X, this includes all the point because we have shifted\n",
    "# So, we are actually making sure that we only have X's where we have values for 'y'\n",
    "# X = X[:-forecast_out + 1]\n",
    "# We actually don't need to do it again, as we have already droped it above.\n",
    "\n",
    "\n",
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model Accuracy is: 0.9775392066724172\n"
     ]
    }
   ],
   "source": [
    "# Since, we got our X's and 'y'\n",
    "# therefore we are now ready for creating our training and testing sets.\n",
    "# Creating training and testing set of data(hopefully here we are using 20% of total data)\n",
    "# X_test and y_test we used to fit our classifier.\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=0.2)\n",
    "# We use, X_train and y_train, to fit our classifiers.\n",
    "\n",
    "# Stuff that is actually goinig to predict again:\n",
    "X_lately = X[-forecast_out:]\n",
    "\n",
    "\n",
    "# Now we need to define the classifier\n",
    "clf = LinearRegression()\n",
    "\n",
    "\n",
    "# Now to fit or train our classifier, we just fit our classifier\n",
    "# fit is synonymous with train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Now we need to see out what the accuracy is\n",
    "# score is synonymous with test\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "\n",
    "print(f'Linear Regression Model Accuracy is: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Accuracy is: 0.8055514658688122\n"
     ]
    }
   ],
   "source": [
    "# Switching The Algorithm From Linear Regression to SVM\n",
    "# Let's now we try to use a different algorithm: SVM, just for testing\n",
    "# Default value of kernel in the SVR() is 'linear', we can also use 'poly' as well:\n",
    "# clf = svm.SVR(kernel = 'poly')\n",
    "\n",
    "clf = svm.SVR()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "print(f'SVM Model Accuracy is: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "> # LECTURE - 04\n",
    ">\n",
    "> ### Forecasting and Predicting: <br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter 'n_jobs' means that how many jobs or how many threads we are willing to run at any given time.\n",
    "\n",
    "And the default for regression is 1.\n",
    "\n",
    "'clf = LinearRegression()' => this is running in linealy. <br>\n",
    "'clf = LinearRegression(n_jobs = 10)' => this will run atleast 10 jobs at a time, parallelly. <br>\n",
    "\n",
    "'clf = LinearRegression(n_jobs = -1)' => this will run as many jobs as possible by our processor.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
